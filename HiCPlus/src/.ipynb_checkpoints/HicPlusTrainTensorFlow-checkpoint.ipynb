{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import os\n",
    "import gzip\n",
    "import lasagne\n",
    "from lasagne import layers\n",
    "from nolearn.lasagne import NeuralNet\n",
    "from lasagne.updates import sgd\n",
    "from utility import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pylab.rcParams['figure.figsize'] = (15, 9)\n",
    "sys.setrecursionlimit(10000)\n",
    "conv2d1_filters_numbers = 8\n",
    "conv2d1_filters_size = 9\n",
    "conv2d2_filters_numbers = 8\n",
    "conv2d2_filters_size = 1\n",
    "conv2d3_filters_numbers = 1\n",
    "conv2d3_filters_size = 5\n",
    "\n",
    "down_sample_ratio = 16\n",
    "learning_rate = 0.00001\n",
    "epochs = 10\n",
    "HiC_max_value = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "low_resolution_samples = np.load(gzip.GzipFile('../data/GM12878_replicate_down16_chr19_22.npy.gz', \"r\")) * down_sample_ratio\n",
    "high_resolution_samples = np.load(gzip.GzipFile('../data/GM12878_replicate_original_chr19_22.npy.gz', \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14689, 1, 40, 40)\n",
      "(14689, 1, 40, 40)\n"
     ]
    }
   ],
   "source": [
    "print(low_resolution_samples.shape)\n",
    "print(high_resolution_samples.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = low_resolution_samples.shape[-1]\n",
    "padding = conv2d1_filters_size + conv2d2_filters_size + conv2d3_filters_size - 3\n",
    "half_padding = padding / 2\n",
    "output_length = sample_size - padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = high_resolution_samples[:, 0, half_padding:(sample_size-half_padding), half_padding:(sample_size-half_padding)]\n",
    "Y = Y.reshape(Y.shape[0], -1)\n",
    "X = low_resolution_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14689, 1, 40, 40)\n",
      "(14689, 784)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net1 = NeuralNet(\n",
    "    layers=[\n",
    "        ('input', layers.InputLayer),\n",
    "        ('conv2d1', layers.Conv2DLayer),\n",
    "        ('conv2d2', layers.Conv2DLayer),\n",
    "        ('conv2d3', layers.Conv2DLayer),\n",
    "        ('output_layer', layers.FlattenLayer),\n",
    "        ],\n",
    "    input_shape=(None, 1, sample_size, sample_size),\n",
    "    conv2d1_num_filters=conv2d1_filters_numbers,\n",
    "    conv2d1_filter_size = (conv2d1_filters_size, conv2d1_filters_size),\n",
    "    conv2d1_nonlinearity=lasagne.nonlinearities.rectify,\n",
    "    conv2d1_W=lasagne.init.GlorotUniform(),\n",
    "    conv2d2_num_filters=conv2d2_filters_numbers,\n",
    "    conv2d2_filter_size = (conv2d2_filters_size, conv2d2_filters_size),\n",
    "    conv2d2_nonlinearity=lasagne.nonlinearities.rectify,\n",
    "    conv2d3_num_filters=conv2d3_filters_numbers,\n",
    "    conv2d3_nonlinearity=lasagne.nonlinearities.rectify,\n",
    "    conv2d3_filter_size = (conv2d3_filters_size, conv2d3_filters_size),\n",
    "    update=sgd,\n",
    "    update_learning_rate = learning_rate,\n",
    "    regression=True,\n",
    "    max_epochs= epochs,\n",
    "    verbose=1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#net1.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_model_name = '../model/test_model'\n",
    "\n",
    "f = file(output_model_name + '.net', 'wb')\n",
    "\n",
    "pickle.dump(net1,f,protocol=pickle.HIGHEST_PROTOCOL)\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
